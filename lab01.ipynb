{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/wikmor/deep-neural-networks/blob/main/lab01.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IPFI7tXJG75N"
      },
      "source": [
        "# Wstęp\n",
        "Pierwsze laboratorium dotyczy wprowadzenia do środowiska PyTorch. Z uwagi na fakt, że przygotowanie środowiska może zająć dłuższą chwilę, część ta jest opisana na końcu niniejszej instrukcji i należy ją wykonać w domu (sekcja [Zadanie domowe](#homework)). Ćwiczenie to nie podlega ocenie, natomiast sugerowane jest wykonanie wszystkich poleceń w celu zapoznania się z podstawami operacji na tensorach. Przed przystąpieniem do realizacji zadań należy wykonać następujące kroki:\n",
        "\n",
        "\n",
        "1.   Uruchomić [Dysk Google](https://drive.google.com/).\n",
        "2.   Przesłać na [Dysk Google](https://drive.google.com/) plik **lab01.ipynb**.\n",
        "3.   Kliknąć prawym przyciskiem myszy na plik **lab01.ipynb** na Dysku Google i wybrać opcję **Otwórz za pomocą** a następnie **Google Colaboratory**. <br/>\n",
        "![colab.png](https://drive.google.com/uc?id=1XzvyggTWZ9j_1I3EegeXK1fu2uBAUSZi)\n",
        "4.   W menu **Google Colab** wybrać opcję **Runtime**, a następnie **Change runtime type**. <br/>\n",
        "![runtime_type.png](https://drive.google.com/uc?id=1Ldp2Je0eFZEUTyGxG3xWoYluq1jCv734)\n",
        "5.   Z rozwijanej listy **Hardware accelerator** wybrać **GPU** a następnie **SAVE**. <br/>\n",
        "![runtime_gpu.png](https://drive.google.com/uc?id=10IY3WEJJ8UVyVHhPkOgZkR6XlPakV5V5)\n",
        "6.   Na końcu należy wybrać opcję **Connect**. <br/>\n",
        "![runtime_gpu.png](https://drive.google.com/uc?id=1juOcGKNVqNJRpoKOg-KCNns15YVHI0vC) <br/>\n",
        "Gdy przycisk **Connect** zamieni się w status widoczny na poniższym obrazku, można rozpocząć pracę. <br/>\n",
        "![runtime_gpu.png](https://drive.google.com/uc?id=1w_ERPHdqD0-_fXBnI6zZR9rTPRujA3c4)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Tensory\n",
        "Tensory są strukturami danych, które są bardzo podobne do tablic i macierzy. W środowisku **PyTorch** tensory są wykorzystywane do zapisywania danych wejściowych i wyjściowych modelu, jak również jego parametrów. Tensory są podobne do tablic **NumPy**, z tą różnicą, że tensory mogą być uruchamiane na kartach graficznych  lub innym wyspecjalizowanym sprzęcie w celu przyspieszenia obliczeń. Przed rozpoczęciem prac należy zaimportować bibliotekę **PyTorch**. Dla przedstawienia pewnych analogii zaimportowana będzie również biblioteka **NumPy**.\n",
        "\n",
        "Ustaw kursor na polu z kodem poniżej i wciśnij przycisk ![image.png](data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABsAAAAYCAIAAACEIhGsAAAA+0lEQVRIDb2VMQ7DMAhFezbPyc7OWWD3Wdi5RW6RnbVSLaE44DRtrXqIIoKf/zfYedjs8ZgNtL8TRYSZEbG8BiIys6peOBtqVFUAaKD4BIARNyfWWiMlRmqtUWxCvIlrC0TomaiqUct15GT/TEz3ziuTogHg6L0jikg6Z993Iko/teBRZkccTWsSRGRd15RLRC6zI47cefa2bWkOInpOR0zXL6V4tpmNdsBzviEyc1w7J6aOjho/dv22MsuyRHWllGFlLronder0YfeY2eQON7P5p9DMJt8UrQluQuPFYzb+K0y+cb1dVZWIvE8RkYiOlfVMf+nOjEd/eXkCRZH2n46ZamIAAAAASUVORK5CYII=)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N589VyKOFCMq"
      },
      "source": [
        "import torch # biblioteka PyTorch\n",
        "import numpy as np # biblioteka NumPy"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mAw-0AZNIFqD"
      },
      "source": [
        "## Inicjalizacja tensora\n",
        "Tensory mogą być inicjalizowane na wiele różnych sposobów. Przykładowo:\n",
        "### Bezpośrednio z listy\n",
        "Tensory mogą być tworzone bezpośrednio z listy. Typ danych jest określany automatycznie.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZWfy7d-bIAxT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4772fda5-1d42-4905-aaad-b5fa4c186848"
      },
      "source": [
        "data_list = [[2,5],[3,6],[4,7]] # lista list z elementami w postaci liczb całkowitych\n",
        "data_tensor = torch.tensor(data_list) # utworzenie tensora z listy\n",
        "data_tensor"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[2, 5],\n",
              "        [3, 6],\n",
              "        [4, 7]])"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Pwr5XljXqla"
      },
      "source": [
        "Utworzony tensor reprezentuje macierz o wymiarach 3x2:\n",
        "\n",
        "$\\begin{bmatrix}\n",
        "2 & 5 \\\\\n",
        "3 & 6 \\\\\n",
        "4 & 7\n",
        "\\end{bmatrix}$\n",
        "\n",
        "Wymiar tensora można sprawdzić następująco:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sNC4MYhPYwEj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "92b25f3c-fecb-43d1-b82a-1417bb9fa6f0"
      },
      "source": [
        "data_tensor.shape # kształt tensora"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([3, 2])"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JgqvUPfnZMpa"
      },
      "source": [
        "Do elementów **shape** odwołujemy się jak w przypadku listy:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TP0h-B5aZDOf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5372138c-e10d-442e-f4b9-f45fa59b5e8e"
      },
      "source": [
        "data_tensor.shape[0]"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kqw-OUL5ZKIs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bb26a463-d65b-44a5-ca82-c450bee63ef0"
      },
      "source": [
        "data_tensor.shape[1]"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fi3lQcVyWX3H"
      },
      "source": [
        "### Z tablicy NumPy\n",
        "Tensory można również tworzyć z tablicy NumPy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9_EJGZQpIC01",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "21af2e20-4c4c-46e9-c5e6-d3d7b1b6770d"
      },
      "source": [
        "numpy_array = np.array(data_list) # tablica NumPy utworzona z listy\n",
        "data_tensor = torch.from_numpy(numpy_array) # tensor utworzony z tablicy NumPy\n",
        "data_tensor"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[2, 5],\n",
              "        [3, 6],\n",
              "        [4, 7]])"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kzmld7uPXAw5"
      },
      "source": [
        "Tensor można również skonwertować do tablicy NumPy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kirprDjqKiQ9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "678dfd29-1092-456a-b784-4a344fe88a07"
      },
      "source": [
        "np_arr = data_tensor.numpy() # tablica NumPy utworzona z tensora\n",
        "np_arr"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[2, 5],\n",
              "       [3, 6],\n",
              "       [4, 7]])"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ph0C8kRoaO_1"
      },
      "source": [
        "---\n",
        "**ZADANIE 1**\n",
        "\n",
        "Uzupełnij kod poniżej, by zmienna **my_tensor** była tensorem reprezentującym następującą macierz:\n",
        "\n",
        "$\\begin{bmatrix}\n",
        "2 & 4 & 6\\\\\n",
        "1 & 3 & 5 \\\\\n",
        "\\end{bmatrix}$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-ZH8987OLoik",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2e983c83-2682-4534-d815-599699042dfe"
      },
      "source": [
        "my_tensor = torch.tensor([[2, 4, 6], [1, 3, 5]])\n",
        "my_tensor"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[2, 4, 6],\n",
              "        [1, 3, 5]])"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FzD3gPVJbXip"
      },
      "source": [
        "---\n",
        "### Z innego tensora\n",
        "Domyślnie nowy tensor zachowuje wszystkie właściwości (kształt, typ danych) tensora przekazanego jako argument. Można nadpisać pewne właściwości podczas tworzenia."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l2ZQ9x1PbWp0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "040241f5-ac95-451a-efb1-d865f7dbe9a5"
      },
      "source": [
        "tensor_2 = torch.ones_like(data_tensor) # tworzenie tensora o wymiarze data_tensor wypełnionego wartościami 1\n",
        "tensor_2"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1, 1],\n",
              "        [1, 1],\n",
              "        [1, 1]])"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sEtwjaqFeI7d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a398400a-1414-4514-b23e-f62129481a4a"
      },
      "source": [
        "tensor_3 = torch.ones_like(data_tensor, dtype=torch.float16) # j.w. z wartościami typu float16\n",
        "tensor_3"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1., 1.],\n",
              "        [1., 1.],\n",
              "        [1., 1.]], dtype=torch.float16)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oNAx1VnSeohu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4a36cf84-25d9-4a8e-89d6-ef34f78d8765"
      },
      "source": [
        "tensor_4 = torch.clone(tensor_3) # kopia tensora tensor_3\n",
        "tensor_4"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1., 1.],\n",
              "        [1., 1.],\n",
              "        [1., 1.]], dtype=torch.float16)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f6-TwelzhYcf"
      },
      "source": [
        "W ostatnim przypadku warto zajrzeć do dokumentacji metody [torch.clone](https://pytorch.org/docs/stable/generated/torch.clone.html) oraz [detach](https://pytorch.org/docs/stable/autograd.html#torch.Tensor.detach)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nF8syRqygKxN"
      },
      "source": [
        "### Z wartościami losowymi bądź stałymi\n",
        "Zmienna **tensor_shape** jest krotką, reprezentującą wymiary tensora. W poniższych funkcjach jest przekazywana jako argument, określający wymiar tworzonego tensora."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ne7cyFmFgJ_C",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "915b2b29-eefb-42f5-e2b6-1e5855b0e440"
      },
      "source": [
        "tensor_shape = (2,3,2) # interpretacja: dwie macierze o wymiarze 3x2\n",
        "tensor_random = torch.rand(tensor_shape) # tensor o losowych wartościach z rozkładu jednorodnego\n",
        "tensor_random"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[0.0973, 0.0194],\n",
              "         [0.0615, 0.3059],\n",
              "         [0.7734, 0.0304]],\n",
              "\n",
              "        [[0.5501, 0.4841],\n",
              "         [0.5691, 0.1861],\n",
              "         [0.8892, 0.2019]]])"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6wv1_bPYeHTp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "943dc546-4035-4bed-c202-4716ee143c22"
      },
      "source": [
        "tensor_ones = torch.ones(tensor_shape) # tensor o wartościach równych 1\n",
        "tensor_ones"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[1., 1.],\n",
              "         [1., 1.],\n",
              "         [1., 1.]],\n",
              "\n",
              "        [[1., 1.],\n",
              "         [1., 1.],\n",
              "         [1., 1.]]])"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TlTPsAhnj1r5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f62cd0e3-a3dd-415e-fed4-0279bb4e9bcb"
      },
      "source": [
        "tensor_zeros = torch.zeros(tensor_shape) # tensor o wartościach równych 0\n",
        "tensor_zeros"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[0., 0.],\n",
              "         [0., 0.],\n",
              "         [0., 0.]],\n",
              "\n",
              "        [[0., 0.],\n",
              "         [0., 0.],\n",
              "         [0., 0.]]])"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PGYDXMHFj_aK"
      },
      "source": [
        "---\n",
        "**ZADANIE 2**\n",
        "\n",
        "Utwórz kształt **my_shape_2**, a na jego podstawie taki tensor **my_tensor_2** o wartościach losowych, by kształt macierzy wyjściowej był taki jak podanej poniżej:\n",
        "\n",
        "$\\begin{bmatrix}\n",
        "0 & 0\\\\\n",
        "0 & 0\\\\\n",
        "0 & 0\\\\\n",
        "\\end{bmatrix}$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XVlHka1mLofx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7dccac13-4dcc-46ff-c171-c2a00130ceaf"
      },
      "source": [
        "my_shape_2 = (1, 3, 2)\n",
        "my_tensor_2 = torch.rand(my_shape_2)\n",
        "my_tensor_2"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[0.8274, 0.8542],\n",
              "         [0.1950, 0.5914],\n",
              "         [0.7466, 0.6507]]])"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lTCNuFQgk71z"
      },
      "source": [
        "---\n",
        "## Atrybuty tensora\n",
        "Atrybuty tensora opisują jego kształt, typ danych oraz urządzenie, na którym tensor jest przechowywany."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LqGIHXCQLodT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "145d136d-285e-4fff-ce5a-425c1d14de5e"
      },
      "source": [
        "tensor_random.shape # kształt"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([2, 3, 2])"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bbzC8sKHLoa5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "043f7228-39df-4ba7-f19f-de245db03c85"
      },
      "source": [
        "tensor_random.dtype # typ danych"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.float32"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xktGPB7wlutO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "31d4a919-89d9-4f22-823f-b2356501602c"
      },
      "source": [
        "tensor_random.device # urządzenie"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cpu')"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bdDKEOXVl1dv"
      },
      "source": [
        "Tensor można przenieść do karty graficznej (GPU) lub innego urządzenia wspierającego operacje [CUDA](https://pl.wikipedia.org/wiki/CUDA) \\(np. [TPU](https://en.wikipedia.org/wiki/Tensor_Processing_Unit)\\), o ile jest dostępne."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ah9SrgQ9mApl"
      },
      "source": [
        "if torch.cuda.is_available(): # metoda sprawdzająca dostępność urządzenia CUDA (GPU lub TPU)\n",
        "  tensor_cuda = tensor_random.to('cuda') # metoda przenosi tensor na wybrane urządzenie\n"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u5r63BEtocuJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0bafa5c6-fad9-459e-eec0-447f81bbb505"
      },
      "source": [
        "tensor_cuda"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[0.0973, 0.0194],\n",
              "         [0.0615, 0.3059],\n",
              "         [0.7734, 0.0304]],\n",
              "\n",
              "        [[0.5501, 0.4841],\n",
              "         [0.5691, 0.1861],\n",
              "         [0.8892, 0.2019]]], device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q0H8N3nmqXGJ"
      },
      "source": [
        "---\n",
        "**ZADANIE 3**\n",
        "\n",
        "Przenieś na GPU tensory z zadania 1 i 2."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1S2XPrKUqlbR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "319325aa-81d7-453f-d0cf-349013d60f14"
      },
      "source": [
        "if torch.cuda.is_available():\n",
        "  my_tensor_cuda = my_tensor.to('cuda')\n",
        "  my_tensor_2_cuda = my_tensor_2.to('cuda')\n",
        "\n",
        "my_tensor_cuda"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[2, 4, 6],\n",
              "        [1, 3, 5]], device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "my_tensor_2_cuda"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QcG9yP87A2HH",
        "outputId": "ac5b4a06-6ff0-4df7-e687-cf451ab9eec1"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[0.8274, 0.8542],\n",
              "         [0.1950, 0.5914],\n",
              "         [0.7466, 0.6507]]], device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zskhODEWqnjR"
      },
      "source": [
        "---\n",
        "# Operacje na tensorach\n",
        "Wiele operacji na tensorach w PyTorch jest bardzo podobnych do operacji w NumPy. Niektóre przykłady będą zawierały analogie przedstawione na tablicach NumPy."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SSZ1eGqnrZvo"
      },
      "source": [
        "### Indeksowanie\n",
        "Najpierw utworzone zostaną dwie zmienne: **tensor** przechowująca tensor o wymiarach 3x4 oraz **array** będącą tablicą NumPy utworzoną na podstawie **tensor**."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N_CoZ0uCrRfj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "efe814d0-794b-49fb-9af0-840bd1fa9664"
      },
      "source": [
        "tensor = torch.zeros(3,4)\n",
        "array = tensor.numpy()\n",
        "print(tensor)\n",
        "print(array)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0.]])\n",
            "[[0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S3yFerI_sRzd"
      },
      "source": [
        "### Modyfikacja elementu o podanym indeksie\n",
        "Indeksy działają analogicznie jak w przypadku [tablic NumPy](https://numpy.org/doc/stable/reference/arrays.indexing.html)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PC9goRyJr7WY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e4eae1fe-8d80-4ff3-ae6f-ce448f93df9a"
      },
      "source": [
        "tensor[1,2] = 1\n",
        "array[1,2] = 1\n",
        "print(tensor)\n",
        "print(array)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0., 0., 0., 0.],\n",
            "        [0., 0., 1., 0.],\n",
            "        [0., 0., 0., 0.]])\n",
            "[[0. 0. 0. 0.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 0. 0. 0.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kkVEnAXPtWpt"
      },
      "source": [
        "### Wydzielenie fragmentu tensora/tablicy\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wqsjuK93th4t",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4afb4da5-3b80-4ff7-b11d-129a7e25cfa3"
      },
      "source": [
        "tensor[:,2:]"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0., 0.],\n",
              "        [1., 0.],\n",
              "        [0., 0.]])"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T89uqRZZtubX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "50f45a49-7fd7-4735-be4f-1731f0de729e"
      },
      "source": [
        "array[1:3,1:4]"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 1., 0.],\n",
              "       [0., 0., 0.]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rrf_H1FpuTYC"
      },
      "source": [
        "### Łączenie tensorów\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qJkjtJR7u8zt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b47cbfbc-7a8d-448b-aa44-3819ca13e707"
      },
      "source": [
        "t1 = torch.zeros(3,2)\n",
        "t2 = torch.ones(3,1)\n",
        "t3 = torch.cat([t1, t2, t1], dim=1)\n",
        "t3"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0., 0., 1., 0., 0.],\n",
              "        [0., 0., 1., 0., 0.],\n",
              "        [0., 0., 1., 0., 0.]])"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QZXvyJlhqxPY"
      },
      "source": [
        "---\n",
        "**ZADANIE 4**\n",
        "\n",
        "Zdefiniuj w postaci tensorów macierze A i B:\n",
        "\n",
        "$A = \\begin{bmatrix}\n",
        "0 & 0 & 0 & 0 & 0\\\\\n",
        "0 & 0 & 0 & 1 & 2\\\\\n",
        "0 & 0 & 0 & 1 & 2\\\\\n",
        "0 & 0 & 0 & 1 & 2\\\\\n",
        "0 & 0 & 0 & 0 & 0\\\\\n",
        "\\end{bmatrix}$\n",
        "\n",
        "$B = \\begin{bmatrix}\n",
        "0 & 0 & 0 & 0 & 0\\\\\n",
        "0 & 0 & 0 & 0 & 0\\\\\n",
        "0 & 0 & 3 & 4 & 0\\\\\n",
        "0 & 0 & 3 & 4 & 0\\\\\n",
        "0 & 0 & 3 & 4 & 0\\\\\n",
        "\\end{bmatrix}$\n",
        "\n",
        "Wykorzystując poznane operacje tensorowe na macierzach A i B, utwórz tensor C, reprezentujący następującą macierz:\n",
        "$C = \\begin{bmatrix}\n",
        "1 & 2 & 3 & 4\\\\\n",
        "1 & 2 & 3 & 4\\\\\n",
        "1 & 2 & 3 & 4\\\\\n",
        "\\end{bmatrix}$\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fs3TS35kuI95",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f2f36dc2-805c-415f-f130-56a0d589a8a6"
      },
      "source": [
        "A = torch.tensor([\n",
        "    [0, 0, 0, 0, 0],\n",
        "    [0, 0, 0, 1, 2],\n",
        "    [0, 0, 0, 1, 2],\n",
        "    [0, 0, 0, 1, 2],\n",
        "    [0, 0, 0, 0, 0]\n",
        "])\n",
        "\n",
        "B = torch.tensor([\n",
        "    [0, 0, 0, 0, 0],\n",
        "    [0, 0, 0, 0, 0],\n",
        "    [0, 0, 3, 4, 0],\n",
        "    [0, 0, 3, 4, 0],\n",
        "    [0, 0, 3, 4, 0]\n",
        "])\n",
        "\n",
        "blok_A = A[1:4, 3:]\n",
        "blok_B = B[2:5, 2:4]\n",
        "\n",
        "C = torch.cat([blok_A, blok_B], dim=1)\n",
        "C"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1, 2, 3, 4],\n",
              "        [1, 2, 3, 4],\n",
              "        [1, 2, 3, 4]])"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3pbKHZ2Kt-2l"
      },
      "source": [
        "---\n",
        "### Mnożenie tensorów\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oWt4oOMOwL0J",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8313a2ed-e943-448b-fbac-0ec5514a6f1e"
      },
      "source": [
        "# zdefiniowanie 3 przykładowych tensorów\n",
        "t1 = torch.tensor([[1,2],[3,4],[2,3]])\n",
        "t2 = torch.tensor([[2,5],[3,6],[4,7]])\n",
        "t3 = torch.tensor([[2,3]])\n",
        "\n",
        "# mnożenie dwóch tensorów (Uwaga! To nie jest mnożenie macierzowe znane z algebry!)\n",
        "t4 = t1.mul(t2)\n",
        "t5 = t1.mul(t3)\n",
        "\n",
        "# mnożenie macierzy przez liczbę\n",
        "t6 = t1.mul(5)\n",
        "print(t1)\n",
        "print(t2)\n",
        "print(t3)\n",
        "print(t4)\n",
        "print(t5)\n",
        "print(t6)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1, 2],\n",
            "        [3, 4],\n",
            "        [2, 3]])\n",
            "tensor([[2, 5],\n",
            "        [3, 6],\n",
            "        [4, 7]])\n",
            "tensor([[2, 3]])\n",
            "tensor([[ 2, 10],\n",
            "        [ 9, 24],\n",
            "        [ 8, 21]])\n",
            "tensor([[ 2,  6],\n",
            "        [ 6, 12],\n",
            "        [ 4,  9]])\n",
            "tensor([[ 5, 10],\n",
            "        [15, 20],\n",
            "        [10, 15]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ix895XVuzb4j",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7981be95-d113-4597-dbd5-02396cd07dc1"
      },
      "source": [
        "# alternatywnie dla powyższych operatorów, można zapisać:\n",
        "t4 = t1 * t2\n",
        "t5 = t1 * t3\n",
        "t6 = t1 * 5\n",
        "print(t4)\n",
        "print(t5)\n",
        "print(t6)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 2, 10],\n",
            "        [ 9, 24],\n",
            "        [ 8, 21]])\n",
            "tensor([[ 2,  6],\n",
            "        [ 6, 12],\n",
            "        [ 4,  9]])\n",
            "tensor([[ 5, 10],\n",
            "        [15, 20],\n",
            "        [10, 15]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Zag88N6006n",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c5151699-2e8e-483f-c749-94132dd2ef73"
      },
      "source": [
        "# transpozycja macierzy\n",
        "print(t1)\n",
        "print(t1.T)\n"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1, 2],\n",
            "        [3, 4],\n",
            "        [2, 3]])\n",
            "tensor([[1, 3, 2],\n",
            "        [2, 4, 3]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w9v1IXGt0Dl9"
      },
      "source": [
        "---\n",
        "**ZADANIE 5**\n",
        "\n",
        "Zdefiniuj t3 jako tensor [[2,3,4]] i powtórz powyższe operacje korzystające z t3. Co możesz zrobić z tensorem t3, żeby operacje wykonały się prawidłowo? Co się stanie, jeśli przeniesiesz wyłącznie t3 na GPU i powtórzysz operacje, które wykonywały się prawidłowo?\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0OGqBDpC2EAd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 159
        },
        "outputId": "03f7e501-ddef-4764-ddd0-bfb1f2defc55"
      },
      "source": [
        "t3 = torch.tensor([[2, 3, 4]])\n",
        "t5 = t1.mul(t3)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "The size of tensor a (2) must match the size of tensor b (3) at non-singleton dimension 1",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-35-162a9b98913d>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mt3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mt5\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (2) must match the size of tensor b (3) at non-singleton dimension 1"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bHfM5C1Yzcvh"
      },
      "source": [
        "---\n",
        "### Mnożenie macierzowe"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TqFbk2B90EMw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ddbd3107-05bf-4557-8545-7fa6770757a5"
      },
      "source": [
        "# Mnożenie macierzowe wykonywane jest w następujący sposób:\n",
        "print('t1: ', t1)\n",
        "print(t2)\n",
        "print(t2.T)\n",
        "print(t1.matmul(t2.T))"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "t1:  tensor([[1, 2],\n",
            "        [3, 4],\n",
            "        [2, 3]])\n",
            "tensor([[2, 5],\n",
            "        [3, 6],\n",
            "        [4, 7]])\n",
            "tensor([[2, 3, 4],\n",
            "        [5, 6, 7]])\n",
            "tensor([[12, 15, 18],\n",
            "        [26, 33, 40],\n",
            "        [19, 24, 29]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MwJdlffv0-li",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "66a31682-7bd5-4992-a2e9-a4ca78a49ae0"
      },
      "source": [
        "# Zapis alternatywny:\n",
        "print(t1 @ t2.T)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[12, 15, 18],\n",
            "        [26, 33, 40],\n",
            "        [19, 24, 29]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "53wbnT4k1UOE"
      },
      "source": [
        "### Operacje \"w miejscu\" (in-place)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WVvrR4iE1ZYS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "675e30be-6c62-47ae-9c72-8c5be7fa53c8"
      },
      "source": [
        "# Uwaga! Operacje w miejscu pomagają oszczędzić pamięć, ale mogą nadpisać wartości potrzebne do wyznaczania gradientu.\n",
        "# Więcej informacji można znaleźć tu: https://pytorch.org/docs/stable/notes/autograd.html#in-place-operations-with-autograd\n",
        "\n",
        "# Operacje w miejscu są zdefiniowane z sufiksem \"_\"\n",
        "print(t1)\n",
        "t1.add_(5)\n",
        "print(t1)\n",
        "t1.mul_(2)\n",
        "print(t1)"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1, 2],\n",
            "        [3, 4],\n",
            "        [2, 3]])\n",
            "tensor([[6, 7],\n",
            "        [8, 9],\n",
            "        [7, 8]])\n",
            "tensor([[12, 14],\n",
            "        [16, 18],\n",
            "        [14, 16]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cxPGNEJ_CYsn"
      },
      "source": [
        "### Pełna lista operacji tensorowych\n",
        "\n",
        "Z pełną listą operacji tensorowych można zapoznać się tutaj:\n",
        "\n",
        "https://pytorch.org/docs/stable/torch.html#\n",
        "\n",
        "---\n",
        "**ZADANIE 6**\n",
        "\n",
        "Na podstawie [dokumentacji PyTorch](https://pytorch.org/docs/stable/torch.html#) znajdź operator, przy pomocy którego zrealizujesz następujące przekształcenia:\n",
        "\n",
        "A.\n",
        "$\\begin{bmatrix}\n",
        "1 & 2 & 3 \\\\\n",
        "4 & 5 & 6 \\\\\n",
        "7 & 8 & 9 \\\\\n",
        "\\end{bmatrix} \\rightarrow\n",
        "\\begin{bmatrix}\n",
        "1 & 0 & 3 \\\\\n",
        "0 & 5 & 0 \\\\\n",
        "7 & 0 & 9 \\\\\n",
        "\\end{bmatrix}\n",
        "$\n",
        "\n",
        "B.\n",
        "$\\begin{bmatrix}\n",
        "2 & 5 & 8 & 3 & 1\\\\\n",
        "9 & 2 & 4 & 5 & 8\\\\\n",
        "4 & 7 & 1 & 2 & 3\\\\\n",
        "2 & 7 & 3 & 6 & 8\\\\\n",
        "1 & 5 & 6 & 9 & 2\\\\\n",
        "\\end{bmatrix} \\rightarrow\n",
        "\\begin{bmatrix}\n",
        "2 & 0 & 1 & 4 & 3\\\\\n",
        "\\end{bmatrix}\n",
        "$\n",
        "\n",
        "C.\n",
        "$\\begin{bmatrix}\n",
        "2 & 5 & 8 & 3 & 1\\\\\n",
        "9 & 2 & 4 & 5 & 8\\\\\n",
        "4 & 7 & 1 & 2 & 3\\\\\n",
        "2 & 7 & 3 & 6 & 8\\\\\n",
        "1 & 5 & 6 & 9 & 2\\\\\n",
        "\\end{bmatrix} \\rightarrow\n",
        "\\begin{bmatrix}\n",
        "8 & 9 & 7 & 8 & 9\\\\\n",
        "\\end{bmatrix}\n",
        "$\n",
        "\n",
        "D.\n",
        "$\\begin{bmatrix}\n",
        "2 & 5 & 8 & 3 & 1\\\\\n",
        "9 & 2 & 4 & 5 & 8\\\\\n",
        "4 & 7 & 1 & 2 & 3\\\\\n",
        "2 & 7 & 3 & 6 & 8\\\\\n",
        "1 & 5 & 6 & 9 & 2\\\\\n",
        "\\end{bmatrix} \\rightarrow\n",
        "\\begin{bmatrix}\n",
        "18 & 26 & 22 & 25 & 22\\\\\n",
        "\\end{bmatrix}\n",
        "$\n",
        "\n",
        "E.\n",
        "$\\begin{bmatrix}\n",
        "2 & 5 & 8 & 3 & 1\\\\\n",
        "9 & 2 & 4 & 5 & 8\\\\\n",
        "4 & 7 & 1 & 2 & 3\\\\\n",
        "2 & 7 & 3 & 6 & 8\\\\\n",
        "1 & 5 & 6 & 9 & 2\\\\\n",
        "\\end{bmatrix} \\rightarrow\n",
        "\\begin{bmatrix}\n",
        "1 & 2 & 3 & 4 & 5 & 6 & 7 & 8 & 9\\\\\n",
        "\\end{bmatrix}\n",
        "$\n",
        "\n",
        "F.\n",
        "$\\begin{bmatrix}\n",
        "2 & 5 & 8 & 3 & 1\\\\\n",
        "9 & 2 & 4 & 5 & 8\\\\\n",
        "4 & 7 & 1 & 2 & 3\\\\\n",
        "2 & 7 & 3 & 6 & 8\\\\\n",
        "1 & 5 & 6 & 9 & 2\\\\\n",
        "\\end{bmatrix} \\rightarrow\n",
        "\\begin{bmatrix}\n",
        "False & True & True & False & False\\\\\n",
        "True & False & False & True & True\\\\\n",
        "False & True & False & False & False\\\\\n",
        "False & True & False & True & True\\\\\n",
        "False & True & True & True & False\\\\\n",
        "\\end{bmatrix}$\n",
        "\n",
        "G.\n",
        "$\\begin{bmatrix}\n",
        "2 & 5 & 8 & 3 & 1\\\\\n",
        "9 & 2 & 4 & 5 & 8\\\\\n",
        "4 & 7 & 1 & 2 & 3\\\\\n",
        "2 & 7 & 3 & 6 & 8\\\\\n",
        "1 & 5 & 6 & 9 & 2\\\\\n",
        "\\end{bmatrix} \\rightarrow\n",
        "\\begin{bmatrix}\n",
        "8 & 5 & 3 & 2 & 1\\\\\n",
        "9 & 8 & 5 & 4 & 2\\\\\n",
        "7 & 4 & 3 & 2 & 1\\\\\n",
        "8 & 7 & 6 & 3 & 2\\\\\n",
        "9 & 6 & 5 & 2 & 1\\\\\n",
        "\\end{bmatrix},\n",
        "\\begin{bmatrix}\n",
        "2 & 1 & 3 & 0 & 4\\\\\n",
        "0 & 4 & 3 & 2 & 1\\\\\n",
        "1 & 0 & 4 & 3 & 2\\\\\n",
        "4 & 1 & 3 & 2 & 0\\\\\n",
        "3 & 2 & 1 & 4 & 0\\\\\n",
        "\\end{bmatrix}$\n",
        "\n",
        "H.\n",
        "$\\begin{bmatrix}\n",
        "2 & 5 & 8 & 3 & 1\\\\\n",
        "9 & 2 & 4 & 5 & 8\\\\\n",
        "4 & 7 & 1 & 2 & 3\\\\\n",
        "2 & 7 & 3 & 6 & 8\\\\\n",
        "1 & 5 & 6 & 9 & 2\\\\\n",
        "\\end{bmatrix} \\rightarrow\n",
        "\\begin{bmatrix}\n",
        "8 & 5 \\\\\n",
        "9 & 8 \\\\\n",
        "7 & 4 \\\\\n",
        "8 & 7 \\\\\n",
        "9 & 6 \\\\\n",
        "\\end{bmatrix},\n",
        "\\begin{bmatrix}\n",
        "2 & 1 \\\\\n",
        "0 & 4 \\\\\n",
        "1 & 0 \\\\\n",
        "4 & 1 \\\\\n",
        "3 & 2 \\\\\n",
        "\\end{bmatrix}$\n",
        "\n",
        "I.\n",
        "$\\begin{bmatrix}\n",
        "2 & 5 & 8 & 3 & 1\\\\\n",
        "9 & 2 & 4 & 5 & 8\\\\\n",
        "4 & 7 & 1 & 2 & 3\\\\\n",
        "2 & 7 & 3 & 6 & 8\\\\\n",
        "1 & 5 & 6 & 9 & 2\\\\\n",
        "\\end{bmatrix} \\rightarrow\n",
        "\\begin{bmatrix}\n",
        "2 & 7 & 15 & 18 & 19\\\\\n",
        "9 & 11 & 15 & 20 & 28\\\\\n",
        "4 & 11 & 12 & 14 & 17\\\\\n",
        "2 & 9 & 12 & 18 & 26\\\\\n",
        "1 & 6 & 12 & 21 & 23\\\\\n",
        "\\end{bmatrix}$\n",
        "\n",
        "J.\n",
        "$\\begin{bmatrix}\n",
        "1 & 2 \\\\\n",
        "2 & 3 \\\\\n",
        "3 & 4 \\\\\n",
        "\\end{bmatrix} \\rightarrow\n",
        "\\begin{bmatrix}\n",
        "1 & 2 & 2 & 3 & 3 & 4 \\\\\n",
        "\\end{bmatrix}\n",
        "$\n",
        "\n",
        "K.\n",
        "$\\begin{bmatrix}\n",
        "2 & 5 & 8 & 3 & 1\\\\\n",
        "9 & 2 & 4 & 5 & 8\\\\\n",
        "4 & 7 & 1 & 2 & 3\\\\\n",
        "2 & 7 & 3 & 6 & 8\\\\\n",
        "1 & 5 & 6 & 9 & 2\\\\\n",
        "\\end{bmatrix} \\rightarrow\n",
        "\\begin{bmatrix}\n",
        "1 & 3 & 8 & 5 & 2\\\\\n",
        "8 & 5 & 4 & 2 & 9\\\\\n",
        "3 & 2 & 1 & 7 & 4\\\\\n",
        "8 & 6 & 3 & 7 & 2\\\\\n",
        "2 & 9 & 6 & 5 & 1\\\\\n",
        "\\end{bmatrix}$\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jhLYW0xQCNkT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4c19d4f1-0a41-469f-b38b-5e509bba5468"
      },
      "source": [
        "#A.\n",
        "A = torch.tensor([[1,2,3],\n",
        "                  [4,5,6],\n",
        "                  [7,8,9]])\n",
        "mask = torch.tensor([[1,0,1],\n",
        "                     [0,1,0],\n",
        "                     [1,0,1]])\n",
        "result_A = A * mask  # lub torch.mul(A, mask)\n",
        "print(result_A)\n",
        "\n",
        "#B.\n",
        "B = torch.tensor([[2,5,8,3,1],\n",
        "                  [9,2,4,5,8],\n",
        "                  [4,7,1,2,3],\n",
        "                  [2,7,3,6,8],\n",
        "                  [1,5,6,9,2]])\n",
        "# Przyjmijmy, że dla każdej kolumny chcemy wybrać element z określonego wiersza.\n",
        "# Indeksy (o kształcie [1, 5]) określą, z którego wiersza pobrać wartość dla danej kolumny.\n",
        "#indices = torch.tensor([[0, -1, 2, 1, 0]])  # przykład – należy dobrać tak, by wynik był [2,0,1,4,3]\n",
        "indices = torch.tensor([[0, 1, 2, 1, 2]])\n",
        "# Jeśli chcemy w niektórych kolumnach uzyskać 0, możemy najpierw stworzyć maskę lub dokonać operacji warunkowej.\n",
        "result_B = B.gather(dim=0, index=indices)  # operator torch.gather\n",
        "print(result_B)\n",
        "\n",
        "#C.\n",
        "# Dla każdej z 5 wierszy pobieramy maksimum\n",
        "max_values, _ = B.max(dim=1)\n",
        "result_C = max_values  # tensor kształtu (5,)\n",
        "print(result_C)\n",
        "\n",
        "#D.\n",
        "print(B.sum(dim=0))\n",
        "\n",
        "#E.\n",
        "print(B.unique(sorted=True))\n",
        "\n",
        "#F.\n",
        "print(B > 4)\n",
        "\n",
        "#G.\n",
        "print(\"G.\", B.sort(descending=True, dim=1))\n",
        "\n",
        "#H.\n",
        "print(\"H.\", B.topk(k=2, dim=1))\n",
        "\n",
        "#I.\n",
        "print(\"I.\", B.cumsum(dim=1))\n",
        "\n",
        "#J.\n",
        "print(\"J.\", B.flatten())\n",
        "\n",
        "#K.\n",
        "print(\"K\", B.flip(dims=[1]))\n"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1, 0, 3],\n",
            "        [0, 5, 0],\n",
            "        [7, 0, 9]])\n",
            "tensor([[2, 2, 1, 5, 3]])\n",
            "tensor([8, 9, 7, 8, 9])\n",
            "tensor([18, 26, 22, 25, 22])\n",
            "tensor([1, 2, 3, 4, 5, 6, 7, 8, 9])\n",
            "tensor([[False,  True,  True, False, False],\n",
            "        [ True, False, False,  True,  True],\n",
            "        [False,  True, False, False, False],\n",
            "        [False,  True, False,  True,  True],\n",
            "        [False,  True,  True,  True, False]])\n",
            "G. torch.return_types.sort(\n",
            "values=tensor([[8, 5, 3, 2, 1],\n",
            "        [9, 8, 5, 4, 2],\n",
            "        [7, 4, 3, 2, 1],\n",
            "        [8, 7, 6, 3, 2],\n",
            "        [9, 6, 5, 2, 1]]),\n",
            "indices=tensor([[2, 1, 3, 0, 4],\n",
            "        [0, 4, 3, 2, 1],\n",
            "        [1, 0, 4, 3, 2],\n",
            "        [4, 1, 3, 2, 0],\n",
            "        [3, 2, 1, 4, 0]]))\n",
            "H. torch.return_types.topk(\n",
            "values=tensor([[8, 5],\n",
            "        [9, 8],\n",
            "        [7, 4],\n",
            "        [8, 7],\n",
            "        [9, 6]]),\n",
            "indices=tensor([[2, 1],\n",
            "        [0, 4],\n",
            "        [1, 0],\n",
            "        [4, 1],\n",
            "        [3, 2]]))\n",
            "I. tensor([[ 2,  7, 15, 18, 19],\n",
            "        [ 9, 11, 15, 20, 28],\n",
            "        [ 4, 11, 12, 14, 17],\n",
            "        [ 2,  9, 12, 18, 26],\n",
            "        [ 1,  6, 12, 21, 23]])\n",
            "J. tensor([2, 5, 8, 3, 1, 9, 2, 4, 5, 8, 4, 7, 1, 2, 3, 2, 7, 3, 6, 8, 1, 5, 6, 9,\n",
            "        2])\n",
            "K tensor([[1, 3, 8, 5, 2],\n",
            "        [8, 5, 4, 2, 9],\n",
            "        [3, 2, 1, 7, 4],\n",
            "        [8, 6, 3, 7, 2],\n",
            "        [2, 9, 6, 5, 1]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8jpef8xqKiyz"
      },
      "source": [
        "<a name=\"homework\"></a>\n",
        "# Zadanie domowe\n",
        "\n",
        "W ramach zadania domowego należy przygotować środowisko uruchomieniowe dla PyTorch. W tym celu należy zainstalować następujące elementy:\n",
        "\n",
        "\n",
        "*   [Python (wersja 3.x)](https://www.python.org/)\n",
        "*   [Sterowniki NVIDIA](https://www.nvidia.com/Download/index.aspx)\n",
        "*   [CUDA Toolkit 9.2-11.0](https://developer.nvidia.com/cuda-zone)\n",
        "*   [PyTorch 1.7.1](https://pytorch.org/)\n",
        "\n",
        "Dla osób nieposiadających GPU zalecane jest korzystanie z Google Colab.\n",
        "\n",
        "Przydatne instrukcje dla następujących systemów:\n",
        "\n",
        "\n",
        "*   [Ubuntu 20.04](https://varhowto.com/install-pytorch-ubuntu-20-04/)\n",
        "*   [Windows 10](https://pub.towardsai.net/installing-pytorch-with-cuda-support-on-windows-10-a38b1134535e)\n",
        "\n",
        "\n",
        "\n"
      ]
    }
  ]
}